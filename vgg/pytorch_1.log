==28811== NVPROF is profiling process 28811, command: python vgg_generator.py 1
==28811== Profiling application: python vgg_generator.py 1
==28811== Profiling result:
"Device","Context","Stream","Kernel","dram_write_transactions","dram_read_transactions"
,,,,,
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply2<softPlusupdateOutput_functor<float>, float, float, unsigned int, int=-2, int=-2>(TensorInfo<softPlusupdateOutput_functor<float>, float>, TensorInfo<float, float>, float, float)",21762,18891
"Tesla V100-DGXS-16GB (0)","1","7","void AvePoolForward<float, float, bool=1>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, int, float*)",12512,152
"Tesla V100-DGXS-16GB (0)","1","7","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",7580,92
"Tesla V100-DGXS-16GB (0)","1","7","volta_scudnn_128x64_relu_small_nn_v1",189451,6077
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",55478,417
"Tesla V100-DGXS-16GB (0)","1","7","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)",349849,63603
"Tesla V100-DGXS-16GB (0)","1","7","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",777461,1049900
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",446669,398028
"Tesla V100-DGXS-16GB (0)","1","7","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",1652,84
"Tesla V100-DGXS-16GB (0)","1","7","volta_scudnn_128x64_relu_interior_nn_v1",284384,1068225
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",270442,174884
"Tesla V100-DGXS-16GB (0)","1","7","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)",4287421,375547
"Tesla V100-DGXS-16GB (0)","1","7","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",612058,11164482
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",403590,369296
"Tesla V100-DGXS-16GB (0)","1","7","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",504,84
"Tesla V100-DGXS-16GB (0)","1","7","volta_scudnn_128x64_relu_small_nn_v1",97963,753671
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,41
"Tesla V100-DGXS-16GB (0)","1","7","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",0,51808
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,0
"Tesla V100-DGXS-16GB (0)","1","7","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,26792
"Tesla V100-DGXS-16GB (0)","1","7","void cudnn::winograd::winograd3x3Kernel<float, float, int=1, int=4, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",27899,1082
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",36,0
"Tesla V100-DGXS-16GB (0)","1","7","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",84,80
"Tesla V100-DGXS-16GB (0)","1","7","volta_scudnn_128x64_relu_interior_nn_v1",22636,23938
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",2150,0
"Tesla V100-DGXS-16GB (0)","1","7","void AvePoolForward<float, float, bool=1>(int, float const *, int, int, int, int, int, int, int, int, int, int, int, int, float*)",18,200
"Tesla V100-DGXS-16GB (0)","1","7","void fft1d_r2c_32<float, float, float2, bool=1, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",1099411,165936
"Tesla V100-DGXS-16GB (0)","1","14","void fft1d_r2c_32<float, float, float2, bool=0, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",25719,6880
"Tesla V100-DGXS-16GB (0)","1","14","volta_gcgemm_64x32_nt",100194,1106092
"Tesla V100-DGXS-16GB (0)","1","14","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=0>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",20,408
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,41
"Tesla V100-DGXS-16GB (0)","1","7","void fft1d_r2c_32<float, float, float2, bool=1, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",1021748,233858
"Tesla V100-DGXS-16GB (0)","1","14","void fft1d_r2c_32<float, float, float2, bool=0, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",23251,6990
"Tesla V100-DGXS-16GB (0)","1","14","volta_gcgemm_64x32_nt",106207,1125821
"Tesla V100-DGXS-16GB (0)","1","14","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=0>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",465,498
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,41
"Tesla V100-DGXS-16GB (0)","1","7","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",19623,289592
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",8,41
"Tesla V100-DGXS-16GB (0)","1","7","void gemv2T_kernel_val<float, float, float, int=128, int=16, int=2, int=4, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",156886,918776
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,41
"Tesla V100-DGXS-16GB (0)","1","7","void gemv2T_kernel_val<float, float, float, int=128, int=16, int=2, int=4, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",351,262403
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,39
"Tesla V100-DGXS-16GB (0)","1","7","void gemv2T_kernel_val<float, float, float, int=128, int=16, int=2, int=4, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",355,262304
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,9
"Tesla V100-DGXS-16GB (0)","1","7","void gemv2T_kernel_val<float, float, float, int=128, int=16, int=2, int=4, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",700,524843
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,41
"Tesla V100-DGXS-16GB (0)","1","7","void gemv2T_kernel_val<float, float, float, int=128, int=16, int=2, int=4, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",816,1049207
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,9
"Tesla V100-DGXS-16GB (0)","1","7","void gemv2T_kernel_val<float, float, float, int=128, int=16, int=2, int=4, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",823,1049271
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply1<ThresholdUpdateOutputIP<float>, float, unsigned int, int=-2>(TensorInfo<ThresholdUpdateOutputIP<float>, float>, float, float)",0,9
"Tesla V100-DGXS-16GB (0)","1","7","void gemv2T_kernel_val<float, float, float, int=128, int=16, int=2, int=4, bool=0>(int, int, float, float const *, int, float const *, int, float, float*, int)",684,512469
"Tesla V100-DGXS-16GB (0)","1","7","void kernelPointwiseApply2<softPlusupdateOutput_functor<float>, float, float, unsigned int, int=-2, int=-2>(TensorInfo<softPlusupdateOutput_functor<float>, float>, TensorInfo<float, float>, float, float)",0,75
